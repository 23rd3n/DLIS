{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f702a1",
   "metadata": {},
   "source": [
    "# Recovering Images from CT Sinograms with a Variational Network\n",
    "\n",
    "In computed tomography (CT), the tomography reconstruction problem is to obtain an image from a set of projections of that image. A projection is formed by drawing a set of parallel rays through the 2D object of interest, assigning the integral of the objectâ€™s contrast along each ray to a single pixel in the projection. A single projection of a 2D object is one dimensional. To enable computed tomography reconstruction of the object, several projections must be acquired, each of them corresponding to a different angle between the rays with respect to the object. A collection of projections at several angles is called a sinogram, which is a linear transform of the original image.\n",
    "(only slightly adapted from https://scikit-image.org/docs/stable/auto_examples/transform/plot_radon_transform.html)\n",
    "\n",
    "\n",
    "The goal of this homework is to implement a variational network that recovers CT images from few measurements. Training a variational network is time intensive, therefore we work with a few images only, and use a small network with only 2 layers per iteration/cascade. This setup save us computational time relative to working with real-world large datasets arising in practical applications.\n",
    "\n",
    "Most of the implementation is set up already. After a brief introduction to CT, your task is to implement the variational network and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d7089a-120b-4120-856e-d6e46ca170b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.fft\n",
    "\n",
    "from radon import get_operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe4842-e5a8-4e00-bbbf-bbd91ac1b8c0",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a22562",
   "metadata": {},
   "source": [
    "Let us first consider the linear forward map $A$, which in this case is the Radon transform. In this concrete example, we collect projections of a single 256x256 image at 32 different angles. The resulting sinogram (measurement $y$) is 256x32 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu' #'cuda' for GPU, 'cpu' otherwise\n",
    "radon_op, fbp_op = get_operators(n_angles=32, image_size=256, circle=True, device=device)\n",
    "\n",
    "#forward model representing a radon transform\n",
    "def A(x):\n",
    "    y = radon_op(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f139864-e71f-48ae-a5f0-67818154c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gray()\n",
    "img = torch.load(data_path+'0')\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f944e-7cd8-4c4c-b983-f51cbbdc3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinogram = A(img.unsqueeze(1))  # unsqueeze because A expects a channel dimension at location 1\n",
    "print(sinogram.shape)\n",
    "plt.imshow(sinogram.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0f3cd-96d7-4f1f-b2ff-c5d93557c64d",
   "metadata": {},
   "source": [
    "To implement a variational network for the CT problem, we need an implementation of the transpose forward map $A^T$ that maps sinograms back to images. Here, we approximate this transform with filtered back-projection (FBP). For this homework problem, you do not have to understand the defails of FBP. All you have to know is that it is an algorithm that takes a sinogram input and returns a coarse reconstruction of the original image as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb48a0f-4d45-4b43-bead-5a0252566a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use filtered back projection as an estimate of A.T\n",
    "def AT(y):\n",
    "    x=fbp_op(y)\n",
    "    x = x.to(torch.float32)\n",
    "    return x\n",
    "\n",
    "reconstruction = AT(sinogram)\n",
    "plt.imshow(reconstruction.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ad450-692c-4a3b-ae56-81d021100ed6",
   "metadata": {},
   "source": [
    "As you can see, the reconstruction exhibits some severe artefacts compared to the ground-truth image. This is because we took a 256x32 dimensional measurement of a 256x256 dimensional object, i.e. we only have a fraction of $\\frac{256 \\cdot 32}{256^2} = \\frac{1}{8}$ of the $256^2$ measurements that would guarantee the possibility of perfect reconstruction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e9d87-f379-4115-b69d-c88eddd1a648",
   "metadata": {},
   "source": [
    "## Homework Problem Starts Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c5cd5-a233-49e6-b92d-9654a46b0489",
   "metadata": {},
   "source": [
    "### Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8001bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataset that returns sinograms and ground-truth images\n",
    "class CTDataSet(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.path))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.load(self.path+str(idx)).to(device)\n",
    "        sino = A(img.unsqueeze(1))\n",
    "        return img.squeeze(), sino.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = CTDataSet(data_path)\n",
    "\n",
    "#Split dataset into 99 imgs for training and 1 img for validation\n",
    "train_set, val_set = torch.utils.data.random_split(data_set,[99,1],generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "#Dataloader\n",
    "train_dl = DataLoader(train_set, batch_size=1)\n",
    "val_dl = DataLoader(val_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64145086",
   "metadata": {},
   "source": [
    "### Variational network\n",
    "\n",
    "The task is to implement a variational network in the cell below. The network consists of num_cascades = 5, i.e., has 5 iterations. The network should output the reconstruction after every cascade (see last cell).\n",
    "\n",
    "The network is initialized as \n",
    "$$\n",
    "x^t = A^T y,\n",
    "$$\n",
    "and implements the iterations\n",
    "$$\n",
    "x^{t+1} = x^t - \\eta (A^T(Ax^t -y) + R_t(x^t)),\n",
    "$$\n",
    "where $R_t$ is a regularizer parameterized as\n",
    "$$\n",
    "R_t(x) = \\sum_{i=1}^k C_{t,1,i}^T relu(C_{t,2,i} x).\n",
    "$$\n",
    "Here, $C_{t,j,i}$ is a convolution with a kernel of size $3\\times 3$. Note that the regularizer is a simple convolutional network that can be implemented with the functions nn.Conv2d() and nn.ReLU(). The parameter $\\eta$ is a trainable parameter, initialize it to $\\eta=0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in code here\n",
    "# you are free to create as many classes as you need\n",
    "\n",
    "\n",
    "\n",
    "#Whole Variational Network    \n",
    "class VarNet(nn.Module):\n",
    "    def __init__(self, num_cascades=5):\n",
    "        super(VarNet, self).__init__()\n",
    "        \n",
    "        # fill in code here\n",
    "        \n",
    "    def forward(self, y):\n",
    "        \n",
    "        # fill in code here\n",
    "         \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e22ad",
   "metadata": {},
   "source": [
    "### Below are funtions to train and test the network\n",
    "\n",
    "You can modify the functions or the hyperparameters for training as you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loss\n",
    "def mse(gt: torch.Tensor, pred:torch.Tensor)-> torch.Tensor:\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(gt,pred)\n",
    "\n",
    "#train function\n",
    "def train_step(model, optimizer, dataloader_sample):\n",
    "    model.train()\n",
    "    \n",
    "    # reset optimizer's gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # define variables\n",
    "    x, y = dataloader_sample\n",
    "      \n",
    "    # get the prediction\n",
    "    pred = model(y.unsqueeze(1))[-1].squeeze(1)\n",
    "    pred_loss = mse(pred, x)\n",
    "    \n",
    "    #one step of training\n",
    "    pred_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return pred_loss.item()\n",
    "\n",
    "#test function\n",
    "def validation_step(model, dataloader_sample): \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        \n",
    "        x, y = dataloader_sample\n",
    "        \n",
    "        # get the prediction\n",
    "        pred = model(y.unsqueeze(1))[-1].squeeze(1)\n",
    "        pred_loss = mse(pred, x)\n",
    "\n",
    "    return pred_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7d084",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "As optimizer, we choose the Adam optimizer (a standard adaptive gradient method). We then train the model for 10 epochs; training for more epochs gives better results, but after 10 epochs we already get a model that works reasonably well for image recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b26e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0)\n",
    "\n",
    "max_epoch = 10\n",
    "mse_train=[]\n",
    "mse_val= []\n",
    "\n",
    "for epoch in tqdm(range(max_epoch)):\n",
    "    # Initialize Loss and Accuracy\n",
    "    train_loss = val_loss= 0.0\n",
    "    \n",
    "    ### Training Phase\n",
    "    \n",
    "    ## Iterate over the train_dataloader\n",
    "    with tqdm(total=len(train_dl)) as pbar:\n",
    "        for sample in train_dl:            \n",
    "            curr_loss = train_step(model, optimizer, sample)\n",
    "            train_loss += curr_loss / len(train_dl) \n",
    "            pbar.update(1)\n",
    "    \n",
    "    mse_train.append(train_loss)\n",
    "\n",
    "\n",
    "    ### Validation Phase \n",
    "    \n",
    "    ## Validation_dataloader\n",
    "    with tqdm(total=len(val_dl)) as pbar:\n",
    "        for sample in val_dl: \n",
    "            curr_loss = validation_step(model, sample)\n",
    "            val_loss += curr_loss / len(val_dl)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    mse_val.append(val_loss) \n",
    "    \n",
    "    print(epoch, train_loss, val_loss)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_val)\n",
    "plt.title('Validation Error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e316fd3b",
   "metadata": {},
   "source": [
    "### Visualization how VarNet reconstructs an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=next(iter(val_dl))  #img from val set\n",
    "\n",
    "#reconstruction\n",
    "with torch.no_grad(): \n",
    "    x, y = sample\n",
    "    pred = model(y.unsqueeze(1))\n",
    "    fbp = AT(y.unsqueeze(1))\n",
    "\n",
    "plt.gray()\n",
    "fig, ax = plt.subplots(1, 7,figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(fbp.squeeze().cpu())\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[0].set_title('FBP') \n",
    "\n",
    "for i in range(5):\n",
    "    ax[i+1].imshow(pred[i].squeeze().cpu())\n",
    "    ax[i+1].set_xticks([])\n",
    "    ax[i+1].set_yticks([])\n",
    "    ax[i+1].set_title('Cascade '+ str(i+1))\n",
    "    \n",
    "ax[6].imshow(x.squeeze().cpu())   \n",
    "ax[6].set_xticks([])\n",
    "ax[6].set_yticks([])\n",
    "ax[6].set_title('Ground Truth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef104f-69ec-4b9a-b91a-cb78ac32ac52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
