{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm  # for nice progress bars\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from unet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./BSDS300\"\n",
    "\n",
    "train_set_dir = f\"{dataset_dir}/images/train\"\n",
    "train_img_files = [f\"{train_set_dir}/{filename}\" for filename in os.listdir(train_set_dir)]\n",
    "\n",
    "test_set_dir = f\"{dataset_dir}/images/test\"\n",
    "test_img_files = [f\"{test_set_dir}/{filename}\" for filename in os.listdir(test_set_dir)]\n",
    "val_img_files = test_img_files[:50]\n",
    "test_img_files = test_img_files[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyImageChunkDataset(Dataset):\n",
    "    def __init__(self, img_files, noise_var, chunk_size):\n",
    "        self.img_files = img_files\n",
    "        self.noise_var = noise_var\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunks_clean, self.chunks_noisy = self.get_clean_and_noisy_chunks()\n",
    "\n",
    "    def get_clean_and_noisy_chunks(self):\n",
    "      chunks_clean = []\n",
    "      chunks_noisy = []\n",
    "      for file in self.img_files:\n",
    "          \n",
    "          img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "          #print(f\"image shape = {img.shape}\")\n",
    "          img = img.astype('float32') / 255.0\n",
    "          height, width = img.shape\n",
    "\n",
    "          # Calculate the number of chunks in each dimension\n",
    "          num_chunks_h = height // self.chunk_size\n",
    "          num_chunks_w = width // self.chunk_size\n",
    "\n",
    "          # Iterate over chunks\n",
    "          for i in range(num_chunks_h):\n",
    "              for j in range(num_chunks_w):\n",
    "                  # Calculate the chunk coordinates\n",
    "                  start_h = i * self.chunk_size\n",
    "                  end_h = start_h + self.chunk_size\n",
    "                  start_w = j * self.chunk_size\n",
    "                  end_w = start_w + self.chunk_size\n",
    "\n",
    "                  # Extract the chunk from the image\n",
    "                  chunk_clean = img[start_h:end_h, start_w:end_w]\n",
    "                  # Generate noise for the chunk\n",
    "                  noise = np.random.normal(0, np.sqrt(self.noise_var), chunk_clean.shape).astype(np.float32)\n",
    "\n",
    "                  # Add the chunk and noisy version to the lists\n",
    "                  chunks_clean.append(chunk_clean)\n",
    "                  chunks_noisy.append(chunk_clean + noise)\n",
    "\n",
    "      return chunks_clean, chunks_noisy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks_clean)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.chunks_noisy[idx], self.chunks_clean[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMetrics:\n",
    "    def __init__(self):\n",
    "        self.total_psnr = 0.0\n",
    "        self.total_ssim = 0.0\n",
    "        self.num_samples = 0\n",
    "\n",
    "    def update(self, output, clean):\n",
    "        mse = torch.mean((output - clean) ** 2)\n",
    "        batch_psnr = 10 * torch.log10(1.0 / mse)\n",
    "        self.total_psnr += batch_psnr\n",
    "        self.num_samples += output.shape[0]\n",
    "\n",
    "    def get_metrics(self):\n",
    "        avg_psnr = self.total_psnr / self.num_samples\n",
    "        return avg_psnr\n",
    "\n",
    "metrics = ImageMetrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_var = 0.005  # more noise makes denoising harder; we suggest you keep this value but you can also experiment with more or less noise\n",
    "train_chunk_size = 128  # depends on your hardware; larger chunks require more memory during gradient computation; we recommend 128\n",
    "\n",
    "train_set = NoisyImageChunkDataset(img_files=train_img_files, noise_var=noise_var, chunk_size=train_chunk_size)\n",
    "# for validation and testing, we do not have to split the images into chunks because we do not have to compute gradients\n",
    "# the images have shape (321, 481) or (481, 321) so we crop them to (321, 321) to facilitate data loading\n",
    "val_set = NoisyImageChunkDataset(img_files=val_img_files, noise_var=noise_var, chunk_size=321)\n",
    "test_set = NoisyImageChunkDataset(img_files=test_img_files, noise_var=noise_var, chunk_size=321)\n",
    "\n",
    "plt.imshow(train_set[0][0], cmap=\"gray\")\n",
    "\n",
    "print(train_set[8][1].shape)\n",
    "\n",
    "batch_size = 1  # depends on your hardware\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more pooling layers and convolutional kernels increase the complexity of the U-Net (see lecture notes)\n",
    "num_pool_layers = 4\n",
    "chans = 64\n",
    "device = \"cuda\"  # set to \"cuda\" or \"cuda:0\" if you have access to a GPU (e.g. via Google Colab)\n",
    "\n",
    "model = Unet(\n",
    "    in_chans=1,  # 1 input channel as we use grayscale images as input\n",
    "    out_chans=1,  # 1 output channel as the model returns grayscale images\n",
    "    num_pool_layers=num_pool_layers,\n",
    "    chans=chans\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-5)  # choose a suitable optimizer form torch.optim; we recommend to use the ADAM optimizer\n",
    "epochs = 5  # how many epochs to train\n",
    "check_val_every_epochs = 5\n",
    "# Define the loss function\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    for imgs_noisy, imgs_clean in tqdm.tqdm(train_loader, desc=\"Training\"): #\n",
    "        imgs_noisy = imgs_noisy.to(device)\n",
    "        imgs_clean = imgs_clean.to(device)\n",
    "\n",
    "        imgs_noisy = imgs_noisy.unsqueeze(1)\n",
    "        imgs_clean = imgs_clean.unsqueeze(1)\n",
    "        \n",
    "        # Normalize the data\n",
    "        mean = imgs_noisy.mean()\n",
    "        std = imgs_noisy.std()\n",
    "        imgs_noisy_norm = (imgs_noisy - mean) / std\n",
    "        #print(imgs_noisy.shape)\n",
    "        #imgs_noisy_norm  = imgs_noisy_norm .unsqueeze(1)\n",
    "        outputs = model(imgs_noisy_norm)\n",
    "\n",
    "        #De-normalize the model output\n",
    "        outputs = outputs * std + mean\n",
    "\n",
    "        loss = criterion(outputs, imgs_clean)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    if e % check_val_every_epochs == 0:\n",
    "        # Disable gradient computation for validation\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0.0\n",
    "            total_psnr = 0.0\n",
    "            num_val_samples = 0\n",
    "\n",
    "            for imgs_noisy, imgs_clean in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "                imgs_noisy = imgs_noisy.to(device)\n",
    "                imgs_clean = imgs_clean.to(device)\n",
    "\n",
    "                imgs_noisy = imgs_noisy.unsqueeze(1)\n",
    "                imgs_clean = imgs_clean.unsqueeze(1)\n",
    "\n",
    "                # Normalize the data\n",
    "                imgs_noisy_norm = (imgs_noisy - mean) / std\n",
    "\n",
    "                # Forward pass\n",
    "                #imgs_noisy_norm = imgs_noisy_norm.unsqueeze(1)\n",
    "                outputs = model(imgs_noisy_norm)\n",
    "\n",
    "                # De-normalize the model output\n",
    "                outputs = outputs * std + mean\n",
    "\n",
    "                # Compute the validation loss\n",
    "                val_loss = criterion(outputs, imgs_clean)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Compute PSNR (Peak Signal-to-Noise Ratio) as a metric\n",
    "                mse = torch.mean((outputs - imgs_clean) ** 2)\n",
    "                psnr = 10 * torch.log10(1.0 / mse)\n",
    "                total_psnr += psnr.item()\n",
    "\n",
    "                num_val_samples += imgs_noisy.size(0)\n",
    "\n",
    "            avg_val_loss = total_val_loss / num_val_samples\n",
    "            avg_psnr = total_psnr / num_val_samples\n",
    "\n",
    "            print(f\"Epoch: {e}, Validation Loss: {avg_val_loss}, PSNR: {avg_psnr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for imgs_noisy, imgs_clean in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        imgs_noisy = imgs_noisy.to(device)\n",
    "        imgs_clean = imgs_clean.to(device)\n",
    "\n",
    "        imgs_noisy = imgs_noisy.unsqueeze(1)\n",
    "        imgs_clean = imgs_clean.unsqueeze(1)\n",
    "\n",
    "        # Normalize the data\n",
    "        mean = imgs_noisy.mean()\n",
    "        std = imgs_noisy.std()\n",
    "        imgs_noisy_norm = (imgs_noisy - mean) / std\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(imgs_noisy_norm)\n",
    "\n",
    "        # De-normalize the model output\n",
    "        outputs = outputs * std + mean\n",
    "\n",
    "        metrics.update(outputs, imgs_clean)\n",
    "\n",
    "# Get the average PSNR and SSIM\n",
    "avg_psnr = metrics.get_metrics()\n",
    "\n",
    "print(f\"Average PSNR: {avg_psnr:.2f}\")\n",
    "\n",
    "# **Average PSNR: 28.36**\n",
    "\n",
    "plt.imshow(outputs[0][0].cpu().numpy(), cmap=\"gray\")\n",
    "\n",
    "\n",
    "plt.imshow(test_set[49][0], cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
